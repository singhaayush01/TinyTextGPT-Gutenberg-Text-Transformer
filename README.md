# Gutenberg Text Transformer ğŸ§ 
A from-scratch implementation of a Transformer-based language model trained on Project Gutenberg books.

## ğŸ“– Overview
This project is part of my journey to understand how Transformer models (like GPT) work from the ground up.
I started by collecting a diverse text dataset and will gradually build a tokenizer, transformer, and text generator.

## ğŸ§© Steps Completed
âœ… Step 1: Downloaded dataset from Project Gutenberg  
â¬œ Step 2: Train tokenizer  
â¬œ Step 3: Build Transformer model  
â¬œ Step 4: Train and generate text  

## ğŸ› ï¸ Tools & Libraries
- Python 3.9
- Requests
- Hugging Face Tokenizers (for later)
- PyTorch (for model training, coming soon)

## ğŸ“‚ Project Structure
